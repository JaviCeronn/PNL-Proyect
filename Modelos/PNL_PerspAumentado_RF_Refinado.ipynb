{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c57c809b",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "434a059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515e0dcf",
   "metadata": {},
   "source": [
    "Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fb529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CONFIGURACIÓN GENERAL\n",
    "# =========================\n",
    "\n",
    "RUTA_TRAIN = \"../Detoxis_train_kaggle.csv\"\n",
    "RUTA_TEST  = \"../Detoxis_test_kaggle.csv\"\n",
    "\n",
    "COL_ID = \"id\"\n",
    "COL_TEXTO_TRAIN = \"text\"\n",
    "COL_TEXTO_TEST  = \"comment\"\n",
    "COL_Y = \"label\"\n",
    "\n",
    "PERSPECTIVE_API_KEY = os.getenv(\"PERSPECTIVE_API_KEY\", \"\")\n",
    "\n",
    "ATRIBUTOS_PERSPECTIVE = [\n",
    "    \"TOXICITY\",\n",
    "    \"INSULT\",\n",
    "    \"THREAT\",\n",
    "    \"PROFANITY\",\n",
    "    \"IDENTITY_ATTACK\",\n",
    "]\n",
    "IDIOMAS = [\"es\"]\n",
    "\n",
    "SEGUNDOS_MIN_ENTRE_LLAMADAS = 0.9\n",
    "MAX_REINTENTOS = 6\n",
    "TIMEOUT = 30\n",
    "\n",
    "CSV_SCORES_TRAIN = \"../train_perspective_scores.csv\"\n",
    "CSV_SCORES_TEST  = \"../test_perspective_scores.csv\"\n",
    "\n",
    "CSV_SUBMISSION = \"submission_Perspective_RF_Gate.csv\"\n",
    "\n",
    "SEMILLA = 42\n",
    "N_SPLITS = 5\n",
    "PASO_UMBRALES = 0.02\n",
    "\n",
    "# Puerta lógica\n",
    "USAR_PUERTA = True\n",
    "DELTA = 0.05  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be437e15",
   "metadata": {},
   "source": [
    "Cargar datos + limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02b60163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (3463, 3) Test: (891, 2)\n",
      "label\n",
      "0    2316\n",
      "1     809\n",
      "2     269\n",
      "3      69\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Pensó: Zumo para restar.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Como les gusta el afeitado en seco a esta gente.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>asi me gusta, que se maten entre ellos y en al...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Loss mas valientes, los que mejor cortan nuest...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Costumbres...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                               text  label\n",
       "0  0                           Pensó: Zumo para restar.      1\n",
       "1  1   Como les gusta el afeitado en seco a esta gente.      1\n",
       "2  2  asi me gusta, que se maten entre ellos y en al...      2\n",
       "3  3  Loss mas valientes, los que mejor cortan nuest...      1\n",
       "4  4                                      Costumbres...      1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(RUTA_TRAIN)\n",
    "test_df  = pd.read_csv(RUTA_TEST)\n",
    "\n",
    "assert COL_ID in train_df.columns\n",
    "assert COL_TEXTO_TRAIN in train_df.columns\n",
    "assert COL_Y in train_df.columns\n",
    "\n",
    "assert COL_ID in test_df.columns\n",
    "assert COL_TEXTO_TEST in test_df.columns\n",
    "\n",
    "train_df[COL_TEXTO_TRAIN] = train_df[COL_TEXTO_TRAIN].fillna(\"\").astype(str)\n",
    "test_df[COL_TEXTO_TEST]   = test_df[COL_TEXTO_TEST].fillna(\"\").astype(str)\n",
    "train_df[COL_Y]           = train_df[COL_Y].astype(int)\n",
    "\n",
    "train_df[COL_ID] = train_df[COL_ID].astype(str)\n",
    "test_df[COL_ID]  = test_df[COL_ID].astype(str)\n",
    "\n",
    "print(\"Train:\", train_df.shape, \"Test:\", test_df.shape)\n",
    "print(train_df[COL_Y].value_counts().sort_index())\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86325d4",
   "metadata": {},
   "source": [
    "Cliente Perspective + caché"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11d5d7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ClientePerspective:\n",
    "    api_key: str\n",
    "    atributos: List[str]\n",
    "    idiomas: List[str]\n",
    "    segundos_min_entre_llamadas: float = 1.0\n",
    "    timeout: int = 30\n",
    "    max_reintentos: int = 6\n",
    "    max_chars_texto: int = 3000\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self._ultimo_t = 0.0\n",
    "        self._url = f\"https://commentanalyzer.googleapis.com/v1alpha1/comments:analyze?key={self.api_key}\"\n",
    "\n",
    "    def _rate_limit(self):\n",
    "        transcurrido = time.time() - self._ultimo_t\n",
    "        if transcurrido < self.segundos_min_entre_llamadas:\n",
    "            time.sleep(self.segundos_min_entre_llamadas - transcurrido)\n",
    "        self._ultimo_t = time.time()\n",
    "\n",
    "    def analizar(self, texto: str) -> Dict[str, float]:\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"Falta PERSPECTIVE_API_KEY en entorno.\")\n",
    "\n",
    "        texto = (texto or \"\")\n",
    "        texto = \" \".join(texto.split())\n",
    "        texto = texto[: self.max_chars_texto]\n",
    "\n",
    "        payload = {\n",
    "            \"comment\": {\"text\": texto},\n",
    "            \"languages\": self.idiomas,\n",
    "            \"requestedAttributes\": {a: {} for a in self.atributos},\n",
    "        }\n",
    "\n",
    "        for intento in range(1, self.max_reintentos + 1):\n",
    "            try:\n",
    "                self._rate_limit()\n",
    "                r = requests.post(self._url, json=payload, timeout=self.timeout)\n",
    "\n",
    "                if r.status_code in (429, 500, 502, 503, 504):\n",
    "                    raise RuntimeError(f\"HTTP {r.status_code}: {r.text[:200]}\")\n",
    "\n",
    "                r.raise_for_status()\n",
    "                js = r.json()\n",
    "\n",
    "                out = {}\n",
    "                attr_scores = js.get(\"attributeScores\", {})\n",
    "                for a in self.atributos:\n",
    "                    v = attr_scores.get(a, {}).get(\"summaryScore\", {}).get(\"value\", np.nan)\n",
    "                    out[a] = float(v) if v is not None else np.nan\n",
    "                return out\n",
    "\n",
    "            except Exception:\n",
    "                if intento == self.max_reintentos:\n",
    "                    return {a: np.nan for a in self.atributos}\n",
    "                time.sleep(min(2 ** intento, 30) + random.random())\n",
    "\n",
    "        return {a: np.nan for a in self.atributos}\n",
    "\n",
    "\n",
    "def crear_o_cargar_scores_perspective(df, ruta_csv, cliente, col_id, col_texto):\n",
    "    if os.path.exists(ruta_csv):\n",
    "        cache = pd.read_csv(ruta_csv)\n",
    "        if col_id not in cache.columns:\n",
    "            raise ValueError(f\"Cache {ruta_csv} sin columna {col_id}\")\n",
    "        cache[col_id] = cache[col_id].astype(str)\n",
    "        ids_cache = set(cache[col_id].tolist())\n",
    "    else:\n",
    "        cache = pd.DataFrame(columns=[col_id] + cliente.atributos)\n",
    "        ids_cache = set()\n",
    "\n",
    "    df = df.copy()\n",
    "    df[col_id] = df[col_id].astype(str)\n",
    "\n",
    "    ids_df = df[col_id].tolist()\n",
    "    por_consultar = df.loc[~df[col_id].isin(ids_cache), [col_id, col_texto]].copy()\n",
    "\n",
    "    print(f\"[Caché] {ruta_csv}: {len(ids_cache)} ya guardados.\")\n",
    "    print(f\"[Consulta] Faltan: {len(por_consultar)} filas.\")\n",
    "\n",
    "    nuevas_filas = []\n",
    "    for _, row in tqdm(por_consultar.iterrows(), total=len(por_consultar), desc=f\"Perspective -> {os.path.basename(ruta_csv)}\"):\n",
    "        rid = str(row[col_id])\n",
    "        texto = str(row[col_texto])\n",
    "        scores = cliente.analizar(texto)\n",
    "        nuevas_filas.append({col_id: rid, **scores})\n",
    "\n",
    "        if len(nuevas_filas) % 50 == 0:\n",
    "            tmp = pd.DataFrame(nuevas_filas)\n",
    "            cache = pd.concat([cache, tmp], ignore_index=True)\n",
    "            cache[col_id] = cache[col_id].astype(str)\n",
    "            cache = cache.drop_duplicates(subset=[col_id], keep=\"last\")\n",
    "            cache.to_csv(ruta_csv, index=False)\n",
    "            nuevas_filas = []\n",
    "\n",
    "    if nuevas_filas:\n",
    "        tmp = pd.DataFrame(nuevas_filas)\n",
    "        cache = pd.concat([cache, tmp], ignore_index=True)\n",
    "        cache[col_id] = cache[col_id].astype(str)\n",
    "        cache = cache.drop_duplicates(subset=[col_id], keep=\"last\")\n",
    "        cache.to_csv(ruta_csv, index=False)\n",
    "\n",
    "    cache[col_id] = cache[col_id].astype(str)\n",
    "    out = cache.set_index(col_id).loc[ids_df].reset_index()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b868ed96",
   "metadata": {},
   "source": [
    "Obtener scores (train + test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3783aad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Caché] ../train_perspective_scores.csv: 3463 ya guardados.\n",
      "[Consulta] Faltan: 0 filas.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b7449d80b0c46b0a3673971eef3e890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Perspective -> train_perspective_scores.csv: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Caché] ../test_perspective_scores.csv: 891 ya guardados.\n",
      "[Consulta] Faltan: 0 filas.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8bf6408d5a145bbb9b2754c4e68dc93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Perspective -> test_perspective_scores.csv: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>TOXICITY</th>\n",
       "      <th>INSULT</th>\n",
       "      <th>THREAT</th>\n",
       "      <th>PROFANITY</th>\n",
       "      <th>IDENTITY_ATTACK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.005272</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.040926</td>\n",
       "      <td>0.023029</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.023311</td>\n",
       "      <td>0.005254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.659969</td>\n",
       "      <td>0.513094</td>\n",
       "      <td>0.673875</td>\n",
       "      <td>0.235672</td>\n",
       "      <td>0.513580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.377512</td>\n",
       "      <td>0.402434</td>\n",
       "      <td>0.348043</td>\n",
       "      <td>0.088724</td>\n",
       "      <td>0.277209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.009739</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.010809</td>\n",
       "      <td>0.000610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  TOXICITY    INSULT    THREAT  PROFANITY  IDENTITY_ATTACK\n",
       "0  0  0.000628  0.004869  0.005272   0.007792         0.000134\n",
       "1  1  0.040926  0.023029  0.005910   0.023311         0.005254\n",
       "2  2  0.659969  0.513094  0.673875   0.235672         0.513580\n",
       "3  3  0.377512  0.402434  0.348043   0.088724         0.277209\n",
       "4  4  0.009739  0.010515  0.005309   0.010809         0.000610"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cliente = ClientePerspective(\n",
    "    api_key=PERSPECTIVE_API_KEY,\n",
    "    atributos=ATRIBUTOS_PERSPECTIVE,\n",
    "    idiomas=IDIOMAS,\n",
    "    segundos_min_entre_llamadas=SEGUNDOS_MIN_ENTRE_LLAMADAS,\n",
    "    timeout=TIMEOUT,\n",
    "    max_reintentos=MAX_REINTENTOS\n",
    ")\n",
    "\n",
    "scores_train_df = crear_o_cargar_scores_perspective(\n",
    "    train_df[[COL_ID, COL_TEXTO_TRAIN]],\n",
    "    CSV_SCORES_TRAIN,\n",
    "    cliente,\n",
    "    col_id=COL_ID,\n",
    "    col_texto=COL_TEXTO_TRAIN\n",
    ")\n",
    "\n",
    "scores_test_df = crear_o_cargar_scores_perspective(\n",
    "    test_df[[COL_ID, COL_TEXTO_TEST]],\n",
    "    CSV_SCORES_TEST,\n",
    "    cliente,\n",
    "    col_id=COL_ID,\n",
    "    col_texto=COL_TEXTO_TEST\n",
    ")\n",
    "\n",
    "scores_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce13450",
   "metadata": {},
   "source": [
    "Features + imputación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3cdb3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOXICITY</th>\n",
       "      <th>INSULT</th>\n",
       "      <th>THREAT</th>\n",
       "      <th>PROFANITY</th>\n",
       "      <th>IDENTITY_ATTACK</th>\n",
       "      <th>long_car</th>\n",
       "      <th>num_pal</th>\n",
       "      <th>exclam</th>\n",
       "      <th>interrog</th>\n",
       "      <th>ratio_mayus</th>\n",
       "      <th>num_links</th>\n",
       "      <th>persp_max</th>\n",
       "      <th>persp_mean</th>\n",
       "      <th>persp_std</th>\n",
       "      <th>persp_num_hi_07</th>\n",
       "      <th>tox_x_prof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.004869</td>\n",
       "      <td>0.005272</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.003739</td>\n",
       "      <td>0.003268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.040926</td>\n",
       "      <td>0.023029</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.023311</td>\n",
       "      <td>0.005254</td>\n",
       "      <td>48.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040926</td>\n",
       "      <td>0.019686</td>\n",
       "      <td>0.014778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.659969</td>\n",
       "      <td>0.513094</td>\n",
       "      <td>0.673875</td>\n",
       "      <td>0.235672</td>\n",
       "      <td>0.513580</td>\n",
       "      <td>82.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.673875</td>\n",
       "      <td>0.519238</td>\n",
       "      <td>0.176208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.377512</td>\n",
       "      <td>0.402434</td>\n",
       "      <td>0.348043</td>\n",
       "      <td>0.088724</td>\n",
       "      <td>0.277209</td>\n",
       "      <td>117.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.402434</td>\n",
       "      <td>0.298784</td>\n",
       "      <td>0.126450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009739</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.010809</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010809</td>\n",
       "      <td>0.007396</td>\n",
       "      <td>0.004395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TOXICITY    INSULT    THREAT  PROFANITY  IDENTITY_ATTACK  long_car  \\\n",
       "0  0.000628  0.004869  0.005272   0.007792         0.000134      24.0   \n",
       "1  0.040926  0.023029  0.005910   0.023311         0.005254      48.0   \n",
       "2  0.659969  0.513094  0.673875   0.235672         0.513580      82.0   \n",
       "3  0.377512  0.402434  0.348043   0.088724         0.277209     117.0   \n",
       "4  0.009739  0.010515  0.005309   0.010809         0.000610      13.0   \n",
       "\n",
       "   num_pal  exclam  interrog  ratio_mayus  num_links  persp_max  persp_mean  \\\n",
       "0      4.0     0.0       0.0     0.083333        0.0   0.007792    0.003739   \n",
       "1     10.0     0.0       0.0     0.020833        0.0   0.040926    0.019686   \n",
       "2     16.0     0.0       0.0     0.012195        0.0   0.673875    0.519238   \n",
       "3     16.0     0.0       0.0     0.017094        0.0   0.402434    0.298784   \n",
       "4      1.0     0.0       0.0     0.076923        0.0   0.010809    0.007396   \n",
       "\n",
       "   persp_std  persp_num_hi_07  tox_x_prof  \n",
       "0   0.003268              0.0    0.000005  \n",
       "1   0.014778              0.0    0.000954  \n",
       "2   0.176208              0.0    0.155536  \n",
       "3   0.126450              0.0    0.033494  \n",
       "4   0.004395              0.0    0.000105  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_aug = train_df.merge(scores_train_df, on=COL_ID, how=\"left\")\n",
    "test_aug  = test_df.merge(scores_test_df,  on=COL_ID, how=\"left\")\n",
    "\n",
    "def anadir_features_basicas(df: pd.DataFrame, col_texto: str) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    txt = out[col_texto].fillna(\"\").astype(str)\n",
    "    out[\"long_car\"] = txt.str.len().astype(float)\n",
    "    out[\"num_pal\"]  = txt.str.split().str.len().astype(float)\n",
    "    out[\"exclam\"]   = txt.str.count(\"!\").astype(float)\n",
    "    out[\"interrog\"] = txt.str.count(r\"\\?\").astype(float)\n",
    "    out[\"ratio_mayus\"] = txt.apply(lambda s: (sum(c.isupper() for c in s) / max(len(s), 1))).astype(float)\n",
    "    out[\"num_links\"] = txt.str.count(r\"http|www\").astype(float)\n",
    "    return out\n",
    "\n",
    "def anadir_features_perspective_derivadas(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    A = ATRIBUTOS_PERSPECTIVE\n",
    "    out[\"persp_max\"]  = out[A].max(axis=1)\n",
    "    out[\"persp_mean\"] = out[A].mean(axis=1)\n",
    "    out[\"persp_std\"]  = out[A].std(axis=1)\n",
    "    out[\"persp_num_hi_07\"] = (out[A] > 0.7).sum(axis=1).astype(float)\n",
    "    if \"TOXICITY\" in out.columns and \"PROFANITY\" in out.columns:\n",
    "        out[\"tox_x_prof\"] = (out[\"TOXICITY\"] * out[\"PROFANITY\"]).astype(float)\n",
    "    return out\n",
    "\n",
    "train_aug = anadir_features_basicas(train_aug, COL_TEXTO_TRAIN)\n",
    "test_aug  = anadir_features_basicas(test_aug,  COL_TEXTO_TEST)\n",
    "\n",
    "COLS_BASE = ATRIBUTOS_PERSPECTIVE + [\"long_car\", \"num_pal\", \"exclam\", \"interrog\", \"ratio_mayus\", \"num_links\"]\n",
    "\n",
    "for df_ in [train_aug, test_aug]:\n",
    "    df_[COLS_BASE] = df_[COLS_BASE].astype(float)\n",
    "    med = df_[COLS_BASE].median(numeric_only=True)\n",
    "    df_[COLS_BASE] = df_[COLS_BASE].fillna(med)\n",
    "\n",
    "train_aug = anadir_features_perspective_derivadas(train_aug)\n",
    "test_aug  = anadir_features_perspective_derivadas(test_aug)\n",
    "\n",
    "COLS_FEATURES = COLS_BASE + [\"persp_max\", \"persp_mean\", \"persp_std\", \"persp_num_hi_07\", \"tox_x_prof\"]\n",
    "\n",
    "for df_ in [train_aug, test_aug]:\n",
    "    df_[COLS_FEATURES] = df_[COLS_FEATURES].astype(float)\n",
    "    med = df_[COLS_FEATURES].median(numeric_only=True)\n",
    "    df_[COLS_FEATURES] = df_[COLS_FEATURES].fillna(med)\n",
    "\n",
    "train_aug[COLS_FEATURES].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32232154",
   "metadata": {},
   "source": [
    "Umbrales + búsqueda de best_thr (OOF) con tus params fijos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "931a2398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5 listo | min/max=0.013/2.415\n",
      "Fold 2/5 listo | min/max=0.014/2.373\n",
      "Fold 3/5 listo | min/max=0.030/2.464\n",
      "Fold 4/5 listo | min/max=0.018/2.396\n",
      "Fold 5/5 listo | min/max=0.022/2.451\n",
      "\n",
      "✅ Umbrales OOF (best_thr): (0.44, 1.18, 1.82)\n",
      "✅ Macro-F1 OOF: 0.49197335007532544\n"
     ]
    }
   ],
   "source": [
    "def aplicar_umbrales(scores: np.ndarray, t1: float, t2: float, t3: float) -> np.ndarray:\n",
    "    return np.where(scores < t1, 0,\n",
    "           np.where(scores < t2, 1,\n",
    "           np.where(scores < t3, 2, 3))).astype(int)\n",
    "\n",
    "def buscar_mejores_umbrales_macro_f1(scores: np.ndarray, y_true: np.ndarray, paso: float = 0.02):\n",
    "    mejor_thr = (1.0, 2.0, 2.6)\n",
    "    mejor_f1 = -1.0\n",
    "    grid = np.arange(0.0, 3.0 + 1e-9, paso)\n",
    "\n",
    "    for t1 in grid:\n",
    "        for t2 in grid:\n",
    "            if t2 <= t1:\n",
    "                continue\n",
    "            for t3 in grid:\n",
    "                if t3 <= t2:\n",
    "                    continue\n",
    "                y_pred = aplicar_umbrales(scores, t1, t2, t3)\n",
    "                f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "                if f1 > mejor_f1:\n",
    "                    mejor_f1 = float(f1)\n",
    "                    mejor_thr = (float(t1), float(t2), float(t3))\n",
    "    return mejor_thr, mejor_f1\n",
    "\n",
    "\n",
    "# Tus hiperparámetros fijos:\n",
    "BEST_PARAMS = {\n",
    "    \"n_estimators\": 1200,\n",
    "    \"max_depth\": None,\n",
    "    \"min_samples_leaf\": 10,\n",
    "    \"min_samples_split\": 13,\n",
    "    \"max_features\": \"sqrt\",\n",
    "    \"bootstrap\": True,\n",
    "}\n",
    "\n",
    "def obtener_oof_scores_con_params_fijos(df_train_aug, cols_features, col_y, params, n_splits=5, random_state=42):\n",
    "    X = df_train_aug[cols_features]\n",
    "    y = df_train_aug[col_y].astype(int).values\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    oof = np.zeros(len(X), dtype=float)\n",
    "\n",
    "    for fold, (idx_tr, idx_va) in enumerate(skf.split(X, y), 1):\n",
    "        X_tr, X_va = X.iloc[idx_tr], X.iloc[idx_va]\n",
    "        y_tr = y[idx_tr].astype(float)\n",
    "\n",
    "        model = RandomForestRegressor(\n",
    "            **params,\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        model.fit(X_tr, y_tr)\n",
    "\n",
    "        s_va = np.clip(model.predict(X_va), 0.0, 3.0)\n",
    "        oof[idx_va] = s_va\n",
    "        print(f\"Fold {fold}/{n_splits} listo | min/max={s_va.min():.3f}/{s_va.max():.3f}\")\n",
    "\n",
    "    return oof\n",
    "\n",
    "oof_scores = obtener_oof_scores_con_params_fijos(\n",
    "    train_aug, COLS_FEATURES, COL_Y, BEST_PARAMS,\n",
    "    n_splits=N_SPLITS, random_state=SEMILLA\n",
    ")\n",
    "\n",
    "best_thr, best_f1 = buscar_mejores_umbrales_macro_f1(oof_scores, train_aug[COL_Y].values, paso=PASO_UMBRALES)\n",
    "\n",
    "print(\"\\n✅ Umbrales OOF (best_thr):\", best_thr)\n",
    "print(\"✅ Macro-F1 OOF:\", best_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc2cca0",
   "metadata": {},
   "source": [
    "Reporte OOF con best_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f13d1b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte OOF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8125    0.7897    0.8010      2316\n",
      "           1     0.3814    0.4512    0.4134       809\n",
      "           2     0.3978    0.2677    0.3200       269\n",
      "           3     0.4189    0.4493    0.4336        69\n",
      "\n",
      "    accuracy                         0.6633      3463\n",
      "   macro avg     0.5027    0.4895    0.4920      3463\n",
      "weighted avg     0.6718    0.6633    0.6657      3463\n",
      "\n",
      "Matriz confusión OOF:\n",
      "[[1829  470   15    2]\n",
      " [ 355  365   74   15]\n",
      " [  61  110   72   26]\n",
      " [   6   12   20   31]]\n",
      "Distribución clases predichas (OOF):\n",
      "0    2251\n",
      "1     957\n",
      "2     181\n",
      "3      74\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pred_oof = aplicar_umbrales(oof_scores, *best_thr)\n",
    "y_true = train_aug[COL_Y].values\n",
    "\n",
    "print(\"Reporte OOF:\")\n",
    "print(classification_report(y_true, pred_oof, digits=4))\n",
    "\n",
    "print(\"Matriz confusión OOF:\")\n",
    "print(confusion_matrix(y_true, pred_oof))\n",
    "\n",
    "print(\"Distribución clases predichas (OOF):\")\n",
    "print(pd.Series(pred_oof).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605a5531",
   "metadata": {},
   "source": [
    "Puerta lógica (expertos binarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c398f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_expertos_binarios(train_aug, cols_features, col_y, random_state=42):\n",
    "    expertos = {}\n",
    "    for a, b in [(0,1), (1,2), (2,3)]:\n",
    "        df_sub = train_aug[train_aug[col_y].isin([a,b])].copy()\n",
    "        Xb = df_sub[cols_features]\n",
    "        yb = (df_sub[col_y].values == b).astype(int)\n",
    "\n",
    "        clf = RandomForestClassifier(\n",
    "            n_estimators=1200,\n",
    "            max_depth=None,\n",
    "            min_samples_leaf=5,\n",
    "            min_samples_split=10,\n",
    "            max_features=\"sqrt\",\n",
    "            bootstrap=True,\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1,\n",
    "            class_weight=\"balanced_subsample\"\n",
    "        )\n",
    "        clf.fit(Xb, yb)\n",
    "        expertos[(a,b)] = clf\n",
    "        print(f\"Experto ({a} vs {b}) entrenado | muestras={len(df_sub)} | %b={yb.mean()*100:.2f}%\")\n",
    "    return expertos\n",
    "\n",
    "\n",
    "def aplicar_umbrales_con_puerta(scores, thr, X_features, expertos, delta=0.03):\n",
    "    t1, t2, t3 = thr\n",
    "    pred = aplicar_umbrales(scores, t1, t2, t3).copy()\n",
    "\n",
    "    idx_01 = np.where(np.abs(scores - t1) <= delta)[0]\n",
    "    idx_12 = np.where(np.abs(scores - t2) <= delta)[0]\n",
    "    idx_23 = np.where(np.abs(scores - t3) <= delta)[0]\n",
    "\n",
    "    if len(idx_01) > 0:\n",
    "        proba_1 = expertos[(0,1)].predict_proba(X_features.iloc[idx_01])[:, 1]\n",
    "        pred[idx_01] = (proba_1 >= 0.5).astype(int)\n",
    "\n",
    "    if len(idx_12) > 0:\n",
    "        proba_2 = expertos[(1,2)].predict_proba(X_features.iloc[idx_12])[:, 1]\n",
    "        pred[idx_12] = np.where(proba_2 >= 0.5, 2, 1)\n",
    "\n",
    "    if len(idx_23) > 0:\n",
    "        proba_3 = expertos[(2,3)].predict_proba(X_features.iloc[idx_23])[:, 1]\n",
    "        pred[idx_23] = np.where(proba_3 >= 0.5, 3, 2)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2e8a26",
   "metadata": {},
   "source": [
    "Entrenar FINAL con tus params + aplicar best_thr (OOF) + puerta opcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfc43d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experto (0 vs 1) entrenado | muestras=3125 | %b=25.89%\n",
      "Experto (1 vs 2) entrenado | muestras=1078 | %b=24.95%\n",
      "Experto (2 vs 3) entrenado | muestras=338 | %b=20.41%\n",
      "Fold 1/5 listo (puerta en VAL)\n",
      "Fold 2/5 listo (puerta en VAL)\n",
      "Fold 3/5 listo (puerta en VAL)\n",
      "Fold 4/5 listo (puerta en VAL)\n",
      "Fold 5/5 listo (puerta en VAL)\n",
      "\n",
      "VAL / OOF (con puerta lógica)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8113    0.7910    0.8010      2316\n",
      "           1     0.3784    0.4425    0.4080       809\n",
      "           2     0.3807    0.2491    0.3011       269\n",
      "           3     0.3735    0.4493    0.4079        69\n",
      "\n",
      "    accuracy                         0.6607      3463\n",
      "   macro avg     0.4860    0.4830    0.4795      3463\n",
      "weighted avg     0.6680    0.6607    0.6626      3463\n",
      "\n",
      "Confusión VAL / OOF (puerta):\n",
      "[[1832  465   17    2]\n",
      " [ 361  358   71   19]\n",
      " [  59  112   67   31]\n",
      " [   6   11   21   31]]\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "TEST (distribución)\n",
      "0    591\n",
      "1    239\n",
      "2     46\n",
      "3     15\n",
      "Name: count, dtype: int64\n",
      "Rango scores_test: 0.01684252002203591 2.4929303673543464\n"
     ]
    }
   ],
   "source": [
    "# Entrenar modelo final con TODO el train usando tus params fijos\n",
    "X_full = train_aug[COLS_FEATURES]\n",
    "y_full = train_aug[COL_Y].astype(float).values\n",
    "\n",
    "modelo_final = RandomForestRegressor(\n",
    "    **BEST_PARAMS,\n",
    "    random_state=SEMILLA,\n",
    "    n_jobs=-1\n",
    ")\n",
    "modelo_final.fit(X_full, y_full)\n",
    "\n",
    "# Scores train/test\n",
    "scores_train = np.clip(modelo_final.predict(X_full), 0.0, 3.0)\n",
    "scores_test  = np.clip(modelo_final.predict(test_aug[COLS_FEATURES]), 0.0, 3.0)\n",
    "\n",
    "# Predicciones con umbrales OOF best_thr \n",
    "if USAR_PUERTA:\n",
    "    expertos = entrenar_expertos_binarios(train_aug, COLS_FEATURES, COL_Y, random_state=SEMILLA)\n",
    "    pred_train = aplicar_umbrales_con_puerta(scores_train, best_thr, X_full, expertos, delta=DELTA)\n",
    "    pred_test  = aplicar_umbrales_con_puerta(scores_test,  best_thr, test_aug[COLS_FEATURES], expertos, delta=DELTA)\n",
    "else:\n",
    "    pred_train = aplicar_umbrales(scores_train, *best_thr)\n",
    "    pred_test  = aplicar_umbrales(scores_test,  *best_thr)\n",
    "\n",
    "def oof_pred_con_puerta(\n",
    "    df_train_aug,\n",
    "    cols_features,\n",
    "    col_y,\n",
    "    base_params,\n",
    "    thr,\n",
    "    n_splits=5,\n",
    "    random_state=42,\n",
    "    delta=0.03\n",
    "):\n",
    "    X = df_train_aug[cols_features]\n",
    "    y = df_train_aug[col_y].astype(int).values\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    pred_oof_gate = np.zeros(len(X), dtype=int)\n",
    "\n",
    "    for fold, (idx_tr, idx_va) in enumerate(skf.split(X, y), 1):\n",
    "        X_tr, X_va = X.iloc[idx_tr], X.iloc[idx_va]\n",
    "        y_tr = y[idx_tr]\n",
    "\n",
    "        # ---- modelo base del fold ----\n",
    "        base = RandomForestRegressor(\n",
    "            **base_params,\n",
    "            random_state=random_state,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        base.fit(X_tr, y_tr.astype(float))\n",
    "        scores_va = np.clip(base.predict(X_va), 0.0, 3.0)\n",
    "\n",
    "        # ---- expertos entrenados SOLO con train-fold ----\n",
    "        expertos = {}\n",
    "        for a, b in [(0,1), (1,2), (2,3)]:\n",
    "            mask = np.isin(y_tr, [a, b])\n",
    "            Xb = X_tr.iloc[mask]\n",
    "            yb = (y_tr[mask] == b).astype(int)\n",
    "\n",
    "            clf = RandomForestClassifier(\n",
    "                n_estimators=base_params[\"n_estimators\"],\n",
    "                max_depth=base_params[\"max_depth\"],\n",
    "                min_samples_leaf=base_params[\"min_samples_leaf\"],\n",
    "                min_samples_split=base_params[\"min_samples_split\"],\n",
    "                max_features=base_params[\"max_features\"],\n",
    "                bootstrap=base_params[\"bootstrap\"],\n",
    "                random_state=random_state,\n",
    "                n_jobs=-1,\n",
    "                class_weight=\"balanced_subsample\"\n",
    "            )\n",
    "            clf.fit(Xb, yb)\n",
    "            expertos[(a, b)] = clf\n",
    "\n",
    "        # ---- aplicar puerta SOLO en val ----\n",
    "        pred_va = aplicar_umbrales_con_puerta(\n",
    "            scores=scores_va,\n",
    "            thr=thr,\n",
    "            X_features=X_va,\n",
    "            expertos=expertos,\n",
    "            delta=delta\n",
    "        )\n",
    "\n",
    "        pred_oof_gate[idx_va] = pred_va\n",
    "        print(f\"Fold {fold}/{n_splits} listo (puerta en VAL)\")\n",
    "\n",
    "    return pred_oof_gate\n",
    "\n",
    "pred_oof_gate = oof_pred_con_puerta(\n",
    "    train_aug,\n",
    "    COLS_FEATURES,\n",
    "    COL_Y,\n",
    "    BEST_PARAMS,\n",
    "    best_thr,\n",
    "    n_splits=N_SPLITS,\n",
    "    random_state=SEMILLA,\n",
    "    delta=DELTA\n",
    ")\n",
    "\n",
    "print(\"\\nVAL / OOF (con puerta lógica)\")\n",
    "print(classification_report(train_aug[COL_Y].values, pred_oof_gate, digits=4))\n",
    "print(\"Confusión VAL / OOF (puerta):\")\n",
    "print(confusion_matrix(train_aug[COL_Y].values, pred_oof_gate))\n",
    "\n",
    "print(\"----------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nTEST (distribución)\")\n",
    "print(pd.Series(pred_test).value_counts().sort_index())\n",
    "print(\"Rango scores_test:\", float(scores_test.min()), float(scores_test.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106c1db4",
   "metadata": {},
   "source": [
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b1c7db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: submission_Perspective_RF_Gate.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id  label\n",
       "0  0      1\n",
       "1  1      1\n",
       "2  2      0\n",
       "3  3      1\n",
       "4  4      0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"id\": test_aug[COL_ID].values,\n",
    "    \"label\": pred_test.astype(int)\n",
    "})\n",
    "\n",
    "submission.to_csv(CSV_SUBMISSION, index=False)\n",
    "print(\"Guardado:\", CSV_SUBMISSION)\n",
    "submission.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ent-Javi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
